"""
Meeting Recorder v2 ‚Äî –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞—Ö–≤–∞—Ç —ç–∫—Ä–∞–Ω–∞ + 2 –∞—É–¥–∏–æ–∫–∞–Ω–∞–ª–∞
- –í–∏–¥–µ–æ: –∑–∞—Ö–≤–∞—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ —ç–∫—Ä–∞–Ω–∞ —á–µ—Ä–µ–∑ mss
- –ê—É–¥–∏–æ 1: –ú–∏–∫—Ä–æ—Ñ–æ–Ω (–≥–æ–ª–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è = "–Ø")
- –ê—É–¥–∏–æ 2: –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫ WASAPI Loopback (–≥–æ–ª–æ—Å —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞)
- –í—ã—Ö–æ–¥: .avi + –æ—Ç–¥–µ–ª—å–Ω—ã–µ WAV —Ñ–∞–π–ª—ã –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
"""
import os
import sys
import time
import threading
import tempfile
from datetime import datetime
from pathlib import Path

import numpy as np
import cv2
import mss
import sounddevice as sd
from scipy.io import wavfile

# PyAudio –¥–ª—è WASAPI Loopback
try:
    import pyaudiowpatch as pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    try:
        import pyaudio
        PYAUDIO_AVAILABLE = True
    except ImportError:
        PYAUDIO_AVAILABLE = False
        print("‚ö†Ô∏è pyaudio/pyaudiowpatch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


# ===== –í–∏–¥–∂–µ—Ç –≤—ã–±–æ—Ä–∞ –æ–±–ª–∞—Å—Ç–∏ —ç–∫—Ä–∞–Ω–∞ =====
from PyQt6.QtWidgets import QWidget, QApplication
from PyQt6.QtCore import Qt, QRect, QPoint
from PyQt6.QtGui import QPainter, QColor, QFont, QPen


class ScreenRegionSelector(QWidget):
    """
    –ü–æ–ª–Ω–æ—ç–∫—Ä–∞–Ω–Ω—ã–π –≤–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–±–ª–∞—Å—Ç–∏ –∑–∞–ø–∏—Å–∏ –º—ã—à–∫–æ–π
    """
    
    def __init__(self, callback=None):
        super().__init__()
        self.callback = callback
        self.selection = None
        self.origin = QPoint()
        self.current_rect = QRect()
        self._drawing = False
        
        # –§–ª–∞–≥–∏ –æ–∫–Ω–∞ - –≤–∞–∂–Ω–æ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–≤–µ—Ä—Ö –≤—Å–µ–≥–æ
        self.setWindowFlags(
            Qt.WindowType.FramelessWindowHint |
            Qt.WindowType.WindowStaysOnTopHint |
            Qt.WindowType.BypassWindowManagerHint
        )
        self.setAttribute(Qt.WidgetAttribute.WA_TranslucentBackground, True)
        self.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose, False)
        self.setCursor(Qt.CursorShape.CrossCursor)
        
        # –†–∞–∑–º–µ—Ä –Ω–∞ –≤—Å–µ –º–æ–Ω–∏—Ç–æ—Ä—ã
        self._setup_geometry()
    
    def _setup_geometry(self):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–∑–º–µ—Ä –Ω–∞ –≤–µ—Å—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —ç–∫—Ä–∞–Ω (–≤—Å–µ –º–æ–Ω–∏—Ç–æ—Ä—ã)"""
        screens = QApplication.screens()
        if not screens:
            return
        
        # –ù–∞—Ö–æ–¥–∏–º –æ–±—â–∏–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –≤—Å–µ—Ö –º–æ–Ω–∏—Ç–æ—Ä–æ–≤
        min_x = min(s.geometry().x() for s in screens)
        min_y = min(s.geometry().y() for s in screens)
        max_x = max(s.geometry().x() + s.geometry().width() for s in screens)
        max_y = max(s.geometry().y() + s.geometry().height() for s in screens)
        
        self._screen_offset_x = min_x
        self._screen_offset_y = min_y
        
        self.setGeometry(min_x, min_y, max_x - min_x, max_y - min_y)
    
    def showFullScreen(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞ –≤–µ—Å—å —ç–∫—Ä–∞–Ω"""
        self._setup_geometry()
        self.show()
        self.raise_()
        self.activateWindow()
        self.setFocus()
    
    def paintEvent(self, event):
        painter = QPainter(self)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)
        
        # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ç—ë–º–Ω—ã–π —Ñ–æ–Ω
        painter.fillRect(self.rect(), QColor(0, 0, 0, 150))
        
        # –ï—Å–ª–∏ –≤—ã–¥–µ–ª—è–µ–º –æ–±–ª–∞—Å—Ç—å
        if self._drawing and not self.current_rect.isNull() and self.current_rect.width() > 5:
            # –û—á–∏—â–∞–µ–º –≤—ã–¥–µ–ª–µ–Ω–Ω—É—é –æ–±–ª–∞—Å—Ç—å
            painter.setCompositionMode(QPainter.CompositionMode.CompositionMode_Clear)
            painter.fillRect(self.current_rect, Qt.GlobalColor.transparent)
            painter.setCompositionMode(QPainter.CompositionMode.CompositionMode_SourceOver)
            
            # –ó–µ–ª—ë–Ω–∞—è —Ä–∞–º–∫–∞
            pen = QPen(QColor(0, 255, 0), 3)
            painter.setPen(pen)
            painter.drawRect(self.current_rect)
            
            # –†–∞–∑–º–µ—Ä
            size_text = f"{self.current_rect.width()} √ó {self.current_rect.height()}"
            painter.setFont(QFont("Arial", 16, QFont.Weight.Bold))
            painter.setPen(QColor(255, 255, 0))
            
            text_y = self.current_rect.y() - 10
            if text_y < 25:
                text_y = self.current_rect.bottom() + 25
            painter.drawText(self.current_rect.x() + 5, text_y, size_text)
        
        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
        painter.setPen(QColor(255, 255, 255))
        painter.setFont(QFont("Arial", 20, QFont.Weight.Bold))
        text = "üéØ –ó–ê–ñ–ú–ò–¢–ï –ª–µ–≤—É—é –∫–Ω–æ–ø–∫—É –º—ã—à–∏ –∏ –≤—ã–¥–µ–ª–∏—Ç–µ –æ–±–ª–∞—Å—Ç—å"
        painter.drawText(self.rect().adjusted(0, 50, 0, 0), 
                        Qt.AlignmentFlag.AlignTop | Qt.AlignmentFlag.AlignHCenter, text)
        
        painter.setFont(QFont("Arial", 14))
        painter.drawText(self.rect().adjusted(0, 90, 0, 0),
                        Qt.AlignmentFlag.AlignTop | Qt.AlignmentFlag.AlignHCenter,
                        "–ù–∞–∂–º–∏—Ç–µ ESC –¥–ª—è –æ—Ç–º–µ–Ω—ã")
    
    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            self.origin = event.pos()
            self.current_rect = QRect(self.origin, self.origin)
            self._drawing = True
            self.update()
    
    def mouseMoveEvent(self, event):
        if self._drawing:
            self.current_rect = QRect(self.origin, event.pos()).normalized()
            self.update()
    
    def mouseReleaseEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton and self._drawing:
            self._drawing = False
            rect = QRect(self.origin, event.pos()).normalized()
            
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä 50x50
            if rect.width() >= 50 and rect.height() >= 50:
                # –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å —É—á—ë—Ç–æ–º —Å–º–µ—â–µ–Ω–∏—è –º–æ–Ω–∏—Ç–æ—Ä–æ–≤
                global_rect = {
                    "left": self._screen_offset_x + rect.x(),
                    "top": self._screen_offset_y + rect.y(),
                    "width": rect.width(),
                    "height": rect.height()
                }
                self.selection = global_rect
                self.hide()
                
                if self.callback:
                    self.callback(global_rect)
            else:
                # –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è –æ–±–ª–∞—Å—Ç—å - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                self.current_rect = QRect()
                self.update()
    
    def keyPressEvent(self, event):
        if event.key() == Qt.Key.Key_Escape:
            self.selection = None
            self.hide()
            if self.callback:
                self.callback(None)


class MeetingRecorder:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤—Å—Ç—Ä–µ—á: —ç–∫—Ä–∞–Ω + –º–∏–∫—Ä–æ—Ñ–æ–Ω + —Å–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫
    """
    
    def __init__(self, output_dir: str = None):
        self.output_dir = Path(output_dir) if output_dir else Path("./records")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–µ–æ
        self.fps = 15
        self.monitor = None
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ
        self.mic_samplerate = 16000
        self.sys_samplerate = 44100
        self.mic_device = None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.is_recording = False
        self._stop_event = threading.Event()
        self._record_system = True
        
        # –ë—É—Ñ–µ—Ä—ã
        self._video_frames = []
        self._mic_audio = []
        self._sys_audio = []
        
        # –ü–æ—Ç–æ–∫–∏
        self._video_thread = None
        self._mic_thread = None
        self._sys_thread = None
        
        # PyAudio –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞
        self._pyaudio = None
        self._loopback_device = None
    
    def get_monitors(self) -> list:
        """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–Ω–∏—Ç–æ—Ä–æ–≤"""
        with mss.mss() as sct:
            monitors = []
            for i, mon in enumerate(sct.monitors):
                if i == 0:
                    continue
                monitors.append({
                    "id": i,
                    "name": f"–ú–æ–Ω–∏—Ç–æ—Ä {i}",
                    "width": mon["width"],
                    "height": mon["height"],
                    "left": mon["left"],
                    "top": mon["top"]
                })
            return monitors
    
    def get_microphones(self) -> list:
        """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–∏–∫—Ä–æ—Ñ–æ–Ω–æ–≤"""
        devices = sd.query_devices()
        mics = []
        for i, dev in enumerate(devices):
            if dev['max_input_channels'] > 0:
                mics.append({
                    "id": i,
                    "name": dev['name'],
                    "channels": dev['max_input_channels'],
                    "is_default": i == sd.default.device[0]
                })
        return mics
    
    def get_loopback_device(self):
        """–ù–∞–π—Ç–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ WASAPI Loopback –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞"""
        if not PYAUDIO_AVAILABLE:
            print("‚ö†Ô∏è PyAudio –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return None
        
        try:
            p = pyaudio.PyAudio()
            
            # –°–ø–æ—Å–æ–± 1: –ò—â–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å isLoopbackDevice (pyaudiowpatch)
            for i in range(p.get_device_count()):
                try:
                    dev = p.get_device_info_by_index(i)
                    if dev.get('isLoopbackDevice', False):
                        print(f"üîä –ù–∞–π–¥–µ–Ω loopback: {dev['name']}")
                        self._loopback_device = dev
                        p.terminate()
                        return dev
                except:
                    continue
            
            # –°–ø–æ—Å–æ–± 2: –ò—â–µ–º WASAPI default speakers –∏ –¥–µ–ª–∞–µ–º –∏–∑ –Ω–µ–≥–æ loopback
            try:
                wasapi_info = p.get_host_api_info_by_type(pyaudio.paWASAPI)
                default_speakers_idx = wasapi_info.get('defaultOutputDevice', -1)
                
                if default_speakers_idx >= 0:
                    speakers = p.get_device_info_by_index(default_speakers_idx)
                    print(f"üîä Default speakers: {speakers['name']}")
                    
                    # –î–ª—è pyaudiowpatch - –∏—â–µ–º loopback –≤–µ—Ä—Å–∏—é
                    for i in range(p.get_device_count()):
                        dev = p.get_device_info_by_index(i)
                        # –ò—â–µ–º loopback —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å –¥–∏–Ω–∞–º–∏–∫–∞–º–∏
                        if (dev.get('isLoopbackDevice', False) or 
                            ('loopback' in dev['name'].lower() and 
                             speakers['name'].split()[0] in dev['name'])):
                            print(f"üîä Loopback –¥–ª—è speakers: {dev['name']}")
                            self._loopback_device = dev
                            p.terminate()
                            return dev
                    
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ loopback, –∏—Å–ø–æ–ª—å–∑—É–µ–º speakers –Ω–∞–ø—Ä—è–º—É—é
                    # (—Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å pyaudiowpatch)
                    self._loopback_device = speakers
                    p.terminate()
                    return speakers
            except Exception as e:
                print(f"‚ö†Ô∏è WASAPI: {e}")
            
            p.terminate()
            return None
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ loopback: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def set_monitor(self, monitor_id: int = 1):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏"""
        with mss.mss() as sct:
            if monitor_id < len(sct.monitors):
                self.monitor = sct.monitors[monitor_id]
            else:
                self.monitor = sct.monitors[1]
    
    def _record_video(self):
        """–ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ"""
        with mss.mss() as sct:
            frame_time = 1.0 / self.fps
            
            while not self._stop_event.is_set():
                start = time.time()
                
                try:
                    img = sct.grab(self.monitor)
                    frame = np.array(img)
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
                    self._video_frames.append(frame)
                except Exception as e:
                    print(f"Video error: {e}")
                
                elapsed = time.time() - start
                if elapsed < frame_time:
                    time.sleep(frame_time - elapsed)
    
    def _record_microphone(self):
        """–ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ —á–µ—Ä–µ–∑ sounddevice"""
        try:
            print(f"üé§ –ó–∞–ø–∏—Å—å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {self.mic_device}, {self.mic_samplerate}Hz")
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –±–ª–æ–∫–∞–º–∏ –ø–æ–∫–∞ –Ω–µ –æ—Å—Ç–∞–Ω–æ–≤—è—Ç
            chunk_duration = 0.1  # 100ms
            chunk_samples = int(self.mic_samplerate * chunk_duration)
            
            stream = sd.InputStream(
                device=self.mic_device,
                samplerate=self.mic_samplerate,
                channels=1,
                dtype='float32',
                blocksize=chunk_samples
            )
            stream.start()
            
            while not self._stop_event.is_set():
                try:
                    data, overflowed = stream.read(chunk_samples)
                    if overflowed:
                        print("‚ö†Ô∏è Mic overflow")
                    self._mic_audio.append(data.copy())
                except Exception as e:
                    print(f"Mic read: {e}")
                    time.sleep(0.1)
            
            stream.stop()
            stream.close()
            print(f"üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω: –∑–∞–ø–∏—Å–∞–Ω–æ {len(self._mic_audio)} —á–∞–Ω–∫–æ–≤")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def _record_system_audio(self):
        """–ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞ —á–µ—Ä–µ–∑ PyAudio WASAPI Loopback"""
        if not PYAUDIO_AVAILABLE:
            print("‚ö†Ô∏è PyAudio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞")
            return
        
        try:
            p = pyaudio.PyAudio()
            
            # –ò—â–µ–º loopback —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            loopback_dev = None
            
            # –ú–µ—Ç–æ–¥ 1: –ò—â–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å isLoopbackDevice
            for i in range(p.get_device_count()):
                try:
                    dev = p.get_device_info_by_index(i)
                    if dev.get('isLoopbackDevice', False):
                        loopback_dev = dev
                        print(f"üîä –ù–∞–π–¥–µ–Ω loopback: {dev['name']}")
                        break
                except:
                    continue
            
            # –ú–µ—Ç–æ–¥ 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º default output —Å loopback=True (pyaudiowpatch)
            if loopback_dev is None:
                try:
                    wasapi_info = p.get_host_api_info_by_type(pyaudio.paWASAPI)
                    default_idx = wasapi_info.get('defaultOutputDevice', -1)
                    if default_idx >= 0:
                        loopback_dev = p.get_device_info_by_index(default_idx)
                        print(f"üîä –ò—Å–ø–æ–ª—å–∑—É–µ–º default output: {loopback_dev['name']}")
                except Exception as e:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å default output: {e}")
            
            if loopback_dev is None:
                print("‚ùå Loopback —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                p.terminate()
                return
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–ø–∏—Å–∏
            channels = max(1, int(loopback_dev.get('maxInputChannels', 2)))
            if channels == 0:
                channels = 2  # –î–ª—è loopback –æ–±—ã—á–Ω–æ —Å—Ç–µ—Ä–µ–æ
            
            rate = int(loopback_dev.get('defaultSampleRate', 44100))
            self.sys_samplerate = rate
            chunk = int(rate * 0.1)  # 100ms
            
            print(f"üîä –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫: {channels}ch, {rate}Hz")
            
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –ø–æ—Ç–æ–∫
            # –î–ª—è pyaudiowpatch –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            try:
                stream = p.open(
                    format=pyaudio.paFloat32,
                    channels=channels,
                    rate=rate,
                    input=True,
                    input_device_index=loopback_dev['index'],
                    frames_per_buffer=chunk,
                    as_loopback=True  # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä pyaudiowpatch!
                )
            except TypeError:
                # –ï—Å–ª–∏ as_loopback –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è (—Å—Ç–∞—Ä—ã–π pyaudio)
                stream = p.open(
                    format=pyaudio.paFloat32,
                    channels=channels,
                    rate=rate,
                    input=True,
                    input_device_index=loopback_dev['index'],
                    frames_per_buffer=chunk
                )
            
            print(f"üîä –ü–æ—Ç–æ–∫ –æ—Ç–∫—Ä—ã—Ç, –∑–∞–ø–∏—Å—ã–≤–∞—é...")
            
            while not self._stop_event.is_set():
                try:
                    data = stream.read(chunk, exception_on_overflow=False)
                    audio_data = np.frombuffer(data, dtype=np.float32)
                    
                    # Stereo -> Mono
                    if channels > 1:
                        try:
                            audio_data = audio_data.reshape(-1, channels)
                            audio_data = np.mean(audio_data, axis=1)
                        except:
                            pass
                    
                    self._sys_audio.append(audio_data.astype(np.float32))
                except Exception as e:
                    if not self._stop_event.is_set():
                        print(f"‚ö†Ô∏è Sys read: {e}")
                    time.sleep(0.05)
            
            stream.stop_stream()
            stream.close()
            p.terminate()
            
            print(f"üîä –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫: –∑–∞–ø–∏—Å–∞–Ω–æ {len(self._sys_audio)} —á–∞–Ω–∫–æ–≤")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def start(self, region: dict = None, mic_device: int = None, record_system: bool = True):
        """
        –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å
        
        Args:
            region: {"left": x, "top": y, "width": w, "height": h} - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!
            mic_device: ID –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
            record_system: –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫
        """
        if self.is_recording:
            print("‚ö†Ô∏è –ó–∞–ø–∏—Å—å —É–∂–µ –∏–¥—ë—Ç")
            return False
        
        if not region:
            print("‚ùå –û–±–ª–∞—Å—Ç—å –∑–∞–ø–∏—Å–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞!")
            return False
        
        # –û—á–∏—Å—Ç–∫–∞
        self._video_frames = []
        self._mic_audio = []
        self._sys_audio = []
        self._stop_event.clear()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–ª–∞—Å—Ç–∏
        self.monitor = region
        self.mic_device = mic_device
        self._record_system = record_system
        
        print(f"‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞—é –∑–∞–ø–∏—Å—å –æ–±–ª–∞—Å—Ç–∏: {region['width']}x{region['height']}")
        print(f"   –ü–æ–∑–∏—Ü–∏—è: ({region['left']}, {region['top']})")
        print(f"   –ú–∏–∫—Ä–æ—Ñ–æ–Ω: {mic_device or 'default'}")
        print(f"   –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫: {'–î–∞' if record_system else '–ù–µ—Ç'}")
        
        self.is_recording = True
        
        # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–æ–≤
        self._video_thread = threading.Thread(target=self._record_video, daemon=True)
        self._mic_thread = threading.Thread(target=self._record_microphone, daemon=True)
        
        self._video_thread.start()
        self._mic_thread.start()
        
        if record_system:
            self._sys_thread = threading.Thread(target=self._record_system_audio, daemon=True)
            self._sys_thread.start()
        
        return True
    
    def stop(self) -> dict:
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª—ã"""
        if not self.is_recording:
            print("‚ö†Ô∏è –ó–∞–ø–∏—Å—å –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞")
            return None
        
        print("‚èπÔ∏è –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –∑–∞–ø–∏—Å—å...")
        self._stop_event.set()
        self.is_recording = False
        
        # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤
        if self._video_thread:
            self._video_thread.join(timeout=3)
        if self._mic_thread:
            self._mic_thread.join(timeout=3)
        if self._sys_thread:
            self._sys_thread.join(timeout=3)
        
        return self._save_recording()
    
    def _save_recording(self) -> dict:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = f"Meeting_{timestamp}"
        
        video_path = str(self.output_dir / f"{base_name}.avi")
        mic_path = str(self.output_dir / f"{base_name}_mic.wav")
        sys_path = str(self.output_dir / f"{base_name}_sys.wav")
        
        result = {"video": None, "mic_audio": None, "sys_audio": None, "base_name": base_name}
        
        # === –í–∏–¥–µ–æ ===
        if self._video_frames:
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é –≤–∏–¥–µ–æ ({len(self._video_frames)} –∫–∞–¥—Ä–æ–≤)...")
            h, w = self._video_frames[0].shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            out = cv2.VideoWriter(video_path, fourcc, self.fps, (w, h))
            for frame in self._video_frames:
                out.write(frame)
            out.release()
            result["video"] = video_path
            print(f"   ‚úÖ {video_path}")
        
        # === –ú–∏–∫—Ä–æ—Ñ–æ–Ω ===
        if self._mic_audio:
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é –º–∏–∫—Ä–æ—Ñ–æ–Ω...")
            mic_data = np.concatenate(self._mic_audio)
            if mic_data.ndim > 1:
                mic_data = mic_data.flatten()
            max_val = np.max(np.abs(mic_data))
            if max_val > 0:
                mic_data = mic_data / max_val * 0.9
            mic_int16 = (mic_data * 32767).astype(np.int16)
            wavfile.write(mic_path, self.mic_samplerate, mic_int16)
            result["mic_audio"] = mic_path
            print(f"   ‚úÖ {mic_path}")
        
        # === –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫ ===
        if self._sys_audio:
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é —Å–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫...")
            sys_data = np.concatenate(self._sys_audio)
            if sys_data.ndim > 1:
                sys_data = sys_data.flatten()
            max_val = np.max(np.abs(sys_data))
            if max_val > 0:
                sys_data = sys_data / max_val * 0.9
            sys_int16 = (sys_data * 32767).astype(np.int16)
            wavfile.write(sys_path, self.sys_samplerate, sys_int16)
            result["sys_audio"] = sys_path
            print(f"   ‚úÖ {sys_path}")
        else:
            print("   ‚ö†Ô∏è –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫ –Ω–µ –∑–∞–ø–∏—Å–∞–Ω")
        
        return result
