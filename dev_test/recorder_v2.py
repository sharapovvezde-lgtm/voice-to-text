"""
Meeting Recorder v2 ‚Äî –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞—Ö–≤–∞—Ç —ç–∫—Ä–∞–Ω–∞ + 2 –∞—É–¥–∏–æ–∫–∞–Ω–∞–ª–∞
- –í–∏–¥–µ–æ: –∑–∞—Ö–≤–∞—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ —ç–∫—Ä–∞–Ω–∞ —á–µ—Ä–µ–∑ mss
- –ê—É–¥–∏–æ 1: –ú–∏–∫—Ä–æ—Ñ–æ–Ω (–≥–æ–ª–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è = "–Ø")
- –ê—É–¥–∏–æ 2: –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫ WASAPI Loopback (–≥–æ–ª–æ—Å —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞)
- –í—ã—Ö–æ–¥: .avi + –æ—Ç–¥–µ–ª—å–Ω—ã–µ WAV —Ñ–∞–π–ª—ã –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
"""
import os
import sys
import time
import threading
import tempfile
from datetime import datetime
from pathlib import Path

import numpy as np
import cv2
import mss
import sounddevice as sd
from scipy.io import wavfile

# PyAudio –¥–ª—è WASAPI Loopback
try:
    import pyaudiowpatch as pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    try:
        import pyaudio
        PYAUDIO_AVAILABLE = True
    except ImportError:
        PYAUDIO_AVAILABLE = False
        print("‚ö†Ô∏è pyaudio/pyaudiowpatch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


# ===== –í–∏–¥–∂–µ—Ç –≤—ã–±–æ—Ä–∞ –æ–±–ª–∞—Å—Ç–∏ —ç–∫—Ä–∞–Ω–∞ =====
from PyQt6.QtWidgets import QWidget, QApplication, QRubberBand, QLabel
from PyQt6.QtCore import Qt, QRect, QPoint, QTimer
from PyQt6.QtGui import QPainter, QColor, QFont


class ScreenRegionSelector(QWidget):
    """
    –ü–æ–ª–Ω–æ—ç–∫—Ä–∞–Ω–Ω—ã–π –≤–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–±–ª–∞—Å—Ç–∏ –∑–∞–ø–∏—Å–∏ –º—ã—à–∫–æ–π
    """
    
    def __init__(self, callback=None):
        super().__init__()
        self.callback = callback
        self.selection = None
        self.origin = QPoint()
        self.current_rect = QRect()
        
        # –ü–æ–ª–Ω–æ—ç–∫—Ä–∞–Ω–Ω—ã–π –æ–≤–µ—Ä–ª–µ–π
        self.setWindowFlags(
            Qt.WindowType.FramelessWindowHint |
            Qt.WindowType.WindowStaysOnTopHint |
            Qt.WindowType.Tool
        )
        self.setAttribute(Qt.WidgetAttribute.WA_TranslucentBackground)
        self.setCursor(Qt.CursorShape.CrossCursor)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –≤—Å–µ—Ö –º–æ–Ω–∏—Ç–æ—Ä–æ–≤
        screen = QApplication.primaryScreen()
        geometry = screen.virtualGeometry()
        self.setGeometry(geometry)
        
        self._drawing = False
    
    def paintEvent(self, event):
        painter = QPainter(self)
        
        # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ç—ë–º–Ω—ã–π —Ñ–æ–Ω
        painter.fillRect(self.rect(), QColor(0, 0, 0, 120))
        
        # –ï—Å–ª–∏ –≤—ã–¥–µ–ª—è–µ–º –æ–±–ª–∞—Å—Ç—å - —Ä–∏—Å—É–µ–º –µ—ë
        if self._drawing and not self.current_rect.isNull():
            # –û—á–∏—â–∞–µ–º –≤—ã–¥–µ–ª–µ–Ω–Ω—É—é –æ–±–ª–∞—Å—Ç—å (–¥–µ–ª–∞–µ–º –µ—ë –ø—Ä–æ–∑—Ä–∞—á–Ω–æ–π)
            painter.setCompositionMode(QPainter.CompositionMode.CompositionMode_Clear)
            painter.fillRect(self.current_rect, Qt.GlobalColor.transparent)
            painter.setCompositionMode(QPainter.CompositionMode.CompositionMode_SourceOver)
            
            # –†–∞–º–∫–∞ –≤–æ–∫—Ä—É–≥ –≤—ã–¥–µ–ª–µ–Ω–∏—è
            painter.setPen(QColor(0, 200, 0, 255))
            painter.drawRect(self.current_rect)
            
            # –†–∞–∑–º–µ—Ä –æ–±–ª–∞—Å—Ç–∏
            size_text = f"{self.current_rect.width()} x {self.current_rect.height()}"
            painter.setFont(QFont("Arial", 14, QFont.Weight.Bold))
            painter.setPen(QColor(255, 255, 255))
            text_x = self.current_rect.x() + 5
            text_y = self.current_rect.y() - 10 if self.current_rect.y() > 30 else self.current_rect.bottom() + 20
            painter.drawText(text_x, text_y, size_text)
        
        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –≤–≤–µ—Ä—Ö—É
        painter.setPen(QColor(255, 255, 255))
        painter.setFont(QFont("Arial", 16))
        instruction = "üéØ –ó–∞–∂–º–∏—Ç–µ –õ–ö–ú –∏ –≤—ã–¥–µ–ª–∏—Ç–µ –æ–±–ª–∞—Å—Ç—å –¥–ª—è –∑–∞–ø–∏—Å–∏  |  ESC = –æ—Ç–º–µ–Ω–∞"
        painter.drawText(self.rect(), Qt.AlignmentFlag.AlignTop | Qt.AlignmentFlag.AlignHCenter, 
                        f"\n\n{instruction}")
    
    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            self.origin = event.pos()
            self.current_rect = QRect(self.origin, self.origin)
            self._drawing = True
            self.update()
    
    def mouseMoveEvent(self, event):
        if self._drawing:
            self.current_rect = QRect(self.origin, event.pos()).normalized()
            self.update()
    
    def mouseReleaseEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton and self._drawing:
            self._drawing = False
            rect = QRect(self.origin, event.pos()).normalized()
            
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä 100x100
            if rect.width() >= 100 and rect.height() >= 100:
                global_rect = {
                    "left": self.geometry().x() + rect.x(),
                    "top": self.geometry().y() + rect.y(),
                    "width": rect.width(),
                    "height": rect.height()
                }
                self.selection = global_rect
                
                if self.callback:
                    self.callback(global_rect)
            else:
                if self.callback:
                    self.callback(None)
            
            self.close()
    
    def keyPressEvent(self, event):
        if event.key() == Qt.Key.Key_Escape:
            self.selection = None
            if self.callback:
                self.callback(None)
            self.close()


class MeetingRecorder:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤—Å—Ç—Ä–µ—á: —ç–∫—Ä–∞–Ω + –º–∏–∫—Ä–æ—Ñ–æ–Ω + —Å–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫
    """
    
    def __init__(self, output_dir: str = None):
        self.output_dir = Path(output_dir) if output_dir else Path("./records")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–µ–æ
        self.fps = 15
        self.monitor = None
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ
        self.mic_samplerate = 16000
        self.sys_samplerate = 44100
        self.mic_device = None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.is_recording = False
        self._stop_event = threading.Event()
        self._record_system = True
        
        # –ë—É—Ñ–µ—Ä—ã
        self._video_frames = []
        self._mic_audio = []
        self._sys_audio = []
        
        # –ü–æ—Ç–æ–∫–∏
        self._video_thread = None
        self._mic_thread = None
        self._sys_thread = None
        
        # PyAudio –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞
        self._pyaudio = None
        self._loopback_device = None
    
    def get_monitors(self) -> list:
        """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–Ω–∏—Ç–æ—Ä–æ–≤"""
        with mss.mss() as sct:
            monitors = []
            for i, mon in enumerate(sct.monitors):
                if i == 0:
                    continue
                monitors.append({
                    "id": i,
                    "name": f"–ú–æ–Ω–∏—Ç–æ—Ä {i}",
                    "width": mon["width"],
                    "height": mon["height"],
                    "left": mon["left"],
                    "top": mon["top"]
                })
            return monitors
    
    def get_microphones(self) -> list:
        """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–∏–∫—Ä–æ—Ñ–æ–Ω–æ–≤"""
        devices = sd.query_devices()
        mics = []
        for i, dev in enumerate(devices):
            if dev['max_input_channels'] > 0:
                mics.append({
                    "id": i,
                    "name": dev['name'],
                    "channels": dev['max_input_channels'],
                    "is_default": i == sd.default.device[0]
                })
        return mics
    
    def get_loopback_device(self):
        """–ù–∞–π—Ç–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ WASAPI Loopback –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞"""
        if not PYAUDIO_AVAILABLE:
            return None
        
        try:
            p = pyaudio.PyAudio()
            
            # –ò—â–µ–º WASAPI loopback —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            wasapi_info = p.get_host_api_info_by_type(pyaudio.paWASAPI)
            
            # –ò—â–µ–º loopback —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (–æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç "loopback" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏)
            for i in range(p.get_device_count()):
                dev = p.get_device_info_by_index(i)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ WASAPI –∏ loopback
                if dev.get('hostApi') == wasapi_info['index']:
                    # –ò—â–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å isLoopbackDevice –∏–ª–∏ —Å "loopback" –≤ –∏–º–µ–Ω–∏
                    if dev.get('isLoopbackDevice', False) or 'loopback' in dev['name'].lower():
                        self._loopback_device = dev
                        p.terminate()
                        return dev
                    
                    # –ò–ª–∏ —ç—Ç–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤—ã–≤–æ–¥–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    if dev['maxInputChannels'] > 0 and dev['maxOutputChannels'] == 0:
                        # –ú–æ–∂–µ—Ç –±—ã—Ç—å loopback
                        pass
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —è–≤–Ω—ã–π loopback, –±–µ—Ä—ë–º default output device
            default_output = p.get_default_output_device_info()
            self._loopback_device = default_output
            p.terminate()
            return default_output
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ loopback: {e}")
            return None
    
    def set_monitor(self, monitor_id: int = 1):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏"""
        with mss.mss() as sct:
            if monitor_id < len(sct.monitors):
                self.monitor = sct.monitors[monitor_id]
            else:
                self.monitor = sct.monitors[1]
    
    def _record_video(self):
        """–ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ"""
        with mss.mss() as sct:
            frame_time = 1.0 / self.fps
            
            while not self._stop_event.is_set():
                start = time.time()
                
                try:
                    img = sct.grab(self.monitor)
                    frame = np.array(img)
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
                    self._video_frames.append(frame)
                except Exception as e:
                    print(f"Video error: {e}")
                
                elapsed = time.time() - start
                if elapsed < frame_time:
                    time.sleep(frame_time - elapsed)
    
    def _record_microphone(self):
        """–ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
        chunk_samples = int(self.mic_samplerate * 0.1)
        
        def callback(indata, frames, time_info, status):
            if status:
                print(f"Mic: {status}")
            self._mic_audio.append(indata.copy())
        
        try:
            with sd.InputStream(
                device=self.mic_device,
                samplerate=self.mic_samplerate,
                channels=1,
                dtype='float32',
                blocksize=chunk_samples,
                callback=callback
            ):
                while not self._stop_event.is_set():
                    time.sleep(0.05)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}")
    
    def _record_system_audio(self):
        """–ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞ —á–µ—Ä–µ–∑ PyAudio WASAPI"""
        if not PYAUDIO_AVAILABLE:
            print("‚ö†Ô∏è PyAudio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        try:
            p = pyaudio.PyAudio()
            
            # –ü–æ–ª—É—á–∞–µ–º WASAPI host API
            wasapi_info = p.get_host_api_info_by_type(pyaudio.paWASAPI)
            default_speakers = p.get_device_info_by_index(wasapi_info['defaultOutputDevice'])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É loopback
            if not default_speakers.get('isLoopbackDevice', False):
                # –ò—â–µ–º loopback –≤–µ—Ä—Å–∏—é —ç—Ç–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
                for i in range(p.get_device_count()):
                    dev = p.get_device_info_by_index(i)
                    if dev.get('name', '').startswith(default_speakers['name'].split(' (')[0]):
                        if dev.get('isLoopbackDevice', False):
                            default_speakers = dev
                            break
            
            channels = int(default_speakers['maxInputChannels'])
            if channels < 1:
                channels = 2
            
            rate = int(default_speakers['defaultSampleRate'])
            self.sys_samplerate = rate
            
            chunk = int(rate * 0.1)  # 100ms
            
            stream = p.open(
                format=pyaudio.paFloat32,
                channels=channels,
                rate=rate,
                input=True,
                input_device_index=default_speakers['index'],
                frames_per_buffer=chunk
            )
            
            print(f"üîä –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫: {default_speakers['name']}")
            
            while not self._stop_event.is_set():
                try:
                    data = stream.read(chunk, exception_on_overflow=False)
                    audio_data = np.frombuffer(data, dtype=np.float32)
                    
                    # Stereo -> Mono
                    if channels > 1:
                        audio_data = audio_data.reshape(-1, channels)
                        audio_data = np.mean(audio_data, axis=1)
                    
                    self._sys_audio.append(audio_data)
                except Exception as e:
                    print(f"Sys audio read error: {e}")
                    time.sleep(0.1)
            
            stream.stop_stream()
            stream.close()
            p.terminate()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def start(self, region: dict = None, mic_device: int = None, record_system: bool = True):
        """
        –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å
        
        Args:
            region: {"left": x, "top": y, "width": w, "height": h} - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!
            mic_device: ID –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
            record_system: –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫
        """
        if self.is_recording:
            print("‚ö†Ô∏è –ó–∞–ø–∏—Å—å —É–∂–µ –∏–¥—ë—Ç")
            return False
        
        if not region:
            print("‚ùå –û–±–ª–∞—Å—Ç—å –∑–∞–ø–∏—Å–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞!")
            return False
        
        # –û—á–∏—Å—Ç–∫–∞
        self._video_frames = []
        self._mic_audio = []
        self._sys_audio = []
        self._stop_event.clear()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–ª–∞—Å—Ç–∏
        self.monitor = region
        self.mic_device = mic_device
        self._record_system = record_system
        
        print(f"‚ñ∂Ô∏è –ù–∞—á–∏–Ω–∞—é –∑–∞–ø–∏—Å—å –æ–±–ª–∞—Å—Ç–∏: {region['width']}x{region['height']}")
        print(f"   –ü–æ–∑–∏—Ü–∏—è: ({region['left']}, {region['top']})")
        print(f"   –ú–∏–∫—Ä–æ—Ñ–æ–Ω: {mic_device or 'default'}")
        print(f"   –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫: {'–î–∞' if record_system else '–ù–µ—Ç'}")
        
        self.is_recording = True
        
        # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–æ–≤
        self._video_thread = threading.Thread(target=self._record_video, daemon=True)
        self._mic_thread = threading.Thread(target=self._record_microphone, daemon=True)
        
        self._video_thread.start()
        self._mic_thread.start()
        
        if record_system:
            self._sys_thread = threading.Thread(target=self._record_system_audio, daemon=True)
            self._sys_thread.start()
        
        return True
    
    def stop(self) -> dict:
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª—ã"""
        if not self.is_recording:
            print("‚ö†Ô∏è –ó–∞–ø–∏—Å—å –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞")
            return None
        
        print("‚èπÔ∏è –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –∑–∞–ø–∏—Å—å...")
        self._stop_event.set()
        self.is_recording = False
        
        # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤
        if self._video_thread:
            self._video_thread.join(timeout=3)
        if self._mic_thread:
            self._mic_thread.join(timeout=3)
        if self._sys_thread:
            self._sys_thread.join(timeout=3)
        
        return self._save_recording()
    
    def _save_recording(self) -> dict:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = f"Meeting_{timestamp}"
        
        video_path = str(self.output_dir / f"{base_name}.avi")
        mic_path = str(self.output_dir / f"{base_name}_mic.wav")
        sys_path = str(self.output_dir / f"{base_name}_sys.wav")
        
        result = {"video": None, "mic_audio": None, "sys_audio": None, "base_name": base_name}
        
        # === –í–∏–¥–µ–æ ===
        if self._video_frames:
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é –≤–∏–¥–µ–æ ({len(self._video_frames)} –∫–∞–¥—Ä–æ–≤)...")
            h, w = self._video_frames[0].shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            out = cv2.VideoWriter(video_path, fourcc, self.fps, (w, h))
            for frame in self._video_frames:
                out.write(frame)
            out.release()
            result["video"] = video_path
            print(f"   ‚úÖ {video_path}")
        
        # === –ú–∏–∫—Ä–æ—Ñ–æ–Ω ===
        if self._mic_audio:
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é –º–∏–∫—Ä–æ—Ñ–æ–Ω...")
            mic_data = np.concatenate(self._mic_audio)
            if mic_data.ndim > 1:
                mic_data = mic_data.flatten()
            max_val = np.max(np.abs(mic_data))
            if max_val > 0:
                mic_data = mic_data / max_val * 0.9
            mic_int16 = (mic_data * 32767).astype(np.int16)
            wavfile.write(mic_path, self.mic_samplerate, mic_int16)
            result["mic_audio"] = mic_path
            print(f"   ‚úÖ {mic_path}")
        
        # === –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫ ===
        if self._sys_audio:
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é —Å–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫...")
            sys_data = np.concatenate(self._sys_audio)
            if sys_data.ndim > 1:
                sys_data = sys_data.flatten()
            max_val = np.max(np.abs(sys_data))
            if max_val > 0:
                sys_data = sys_data / max_val * 0.9
            sys_int16 = (sys_data * 32767).astype(np.int16)
            wavfile.write(sys_path, self.sys_samplerate, sys_int16)
            result["sys_audio"] = sys_path
            print(f"   ‚úÖ {sys_path}")
        else:
            print("   ‚ö†Ô∏è –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫ –Ω–µ –∑–∞–ø–∏—Å–∞–Ω")
        
        return result
